---
title: "Thesis Clustering"
output: html_notebook
---

Libs
```{r}
library(tidyverse)
library(ggplot2)
library(MASS)
library(data.table)
library(reshape2)
library(dplyr)
library(caret)
library(Hmisc)
library(corrplot)
library(e1071)
library(ResourceSelection)
library(randomForest) # Random Forest
# library(ranger) # Faster Random Forest
library(nnet) # Neural Network
# library(keras) # NN + TensorFlow
library(xgboost)
library(factoextra)
library(mlbench)
library(RColorBrewer)
```

Utils
```{r}
makeAllCorrMatrix <- function(data) {
  correlation <- cor(data)
  rcorrelation <- rcorr(as.matrix(data))
  # Standard Cor with 5 Clustering
  corrplot(
  correlation,
  order = "hclust",
  addrect = 5,
  title = "Standard Cor with 5 Clustering",
  mar = c(0, 0, 1, 0)
  )
  # Mixed Cor
  corrplot.mixed(
  correlation,
  lower.col = "black",
  number.cex = 0.55,
  tl.cex = 0.4,
  upper = "color",
  order = "hclust",
  tl.col = "black",
  tl.srt = 45,
  title = "Mixed Cor",
  mar = c(0, 0, 1, 0)
  )
  # Insignificant correlation are crossed
  corrplot(
  rcorrelation$r,
  type = "upper",
  order = "hclust",
  p.mat = rcorrelation$P,
  sig.level = 0.01,
  insig = "pch",
  title = "Insignificant Crossed",
  mar = c(0, 0, 1, 0)
  )
  # HeatMap
  col <- colorRampPalette(c("blue", "white", "red"))(20)
  heatmap(x = correlation, col = col, symm = TRUE)
  mtest <- cor.mtest(truth_test, conf.level = .95)
  # Visualize Confidence Intervals
  corrplot(
  correlation,
  p.mat = mtest$p,
  method = "color",
  type = "upper",
  sig.level = c(.001, .01, .05),
  pch.cex = .9,
  insig = "label_sig",
  pch.col = "white",
  order = "hclust",
  title = "Confidence Intervals",
  mar = c(0, 0, 1, 0)
  )
}

flattenCorrMatrix <- function(cormat, pmat) {
  ut <- upper.tri(cormat)
  data.frame(
    row = rownames(cormat)[row(cormat)[ut]],
    column = rownames(cormat)[col(cormat)[ut]],
    cor  =(cormat)[ut],
    p = pmat[ut]
    )
}

importanceRF <- function(rfmodel) {
  # Get importance
  importance <- importance(rfmodel)
  varImportance <- data.frame(Variables = row.names(importance),
  Importance = round(importance[, 'MeanDecreaseGini'], 2))
  
  # Create a rank variable based on importance
  rankImportance <- varImportance %>%
  mutate(Rank = paste0('#', dense_rank(desc(Importance))))
  
  # Use ggplot2 to visualize the relative importance of variables
  ggplot(rankImportance, aes(x = reorder(Variables, Importance),
  y = Importance)) +
  geom_bar(stat = 'identity', colour = 'black') +
  geom_text(
  aes(x = Variables, y = 0.5, label = Rank),
  hjust = 0,
  vjust = 0.55,
  size = 4,
  colour = 'lavender',
  fontface = 'bold'
  ) +
  labs(x = 'Variables', title = 'Relative Variable Importance') +
  coord_flip() +
  theme_minimal()
}
```

Loading the Data - lies
```{r}
filenames_L_train <- list.files("./df/deceptive/train", pattern="*.csv", full.names=TRUE)
filenames_L_test <- list.files("./df/deceptive/test", pattern="*.csv", full.names=TRUE)
lies_train <- rbindlist(lapply(filenames_L_train, fread))
lies_test <- rbindlist(lapply(filenames_L_test, fread))

# Remove Useless Columns
lies_train <- lies_train[,-c(1:5)]
lies_test <- lies_test[,-c(1:5)]

# remove all cols with all 0s
lies_train <- lies_train[rowSums(lies_train) !=0, ]
lies_test <- lies_test[rowSums(lies_test) !=0, ]

# Add "deceptive" to cols
lies_test$truthful <- rep(0, nrow(lies_test))
lies_test$truthful <- factor(lies_test$truthful)
lies_train$truthful <- rep(0, nrow(lies_train))
lies_train$truthful <- factor(lies_train$truthful)

# Select Intensity Columns
lint_train <- lies_train[,c(1:17, 36)]
lint_test <- lies_test[,c(1:17, 36)]

# Select Presence Columns
plies_train <- lies_train[,-c(1:17)]
plies_test <- lies_test[,-c(1:17)]
```

Loading the Data - truth
```{r}
filenames_T_train <- list.files("./df/truthful/train", pattern="*.csv", full.names=TRUE)
filenames_T_test <- list.files("./df/truthful/test", pattern="*.csv", full.names=TRUE)
truth_train <- rbindlist(lapply(filenames_T_train, fread))
truth_test <- rbindlist(lapply(filenames_T_test, fread))

# Remove Useless Columns
truth_train <- truth_train[,-c(1:5)]
truth_test <- truth_test[,-c(1:5)]

# remove all cols with all 0s
truth_train <- truth_train[rowSums(truth_train) !=0, ]
truth_test <- truth_test[rowSums(truth_test) !=0, ]

# Add "truthful" to cols
truth_test$truthful <- rep(1, nrow(truth_test))
truth_test$truthful <- factor(truth_test$truthful)
truth_train$truthful <- rep(1, nrow(truth_train))
truth_train$truthful <- factor(truth_train$truthful)

# Select Intensity Columns
tint_train <- truth_train[,c(1:17, 36)]
tint_test <- truth_test[,c(1:17, 36)]

# Select Presence Columns
ptruth_train <- truth_train[,-c(1:17)]
ptruth_test <- truth_test[,-c(1:17)]
```

Create Train & Test set
```{r}
# Presence
trainDF <- rbind(ptruth_train, plies_train)
testDF <- rbind(ptruth_test, plies_test)

# Intensity
trainIntDF <- rbind(tint_train, lint_train)
testIntDF  <- rbind(tint_test, lint_test)

# Together
ALL_train <- rbind(truth_train, lies_train)
ALL_test <- rbind(truth_test, lies_test)
```


OLD Train & Test Set
```{r}
# # merge train and test
# DF <- rbind(truth, lies)
# #write.csv2(DF, "./df/presence.csv", row.names = F)
# splitIndex <- createDataPartition(DF[,truthful], p = .75, list = FALSE, times = 1)
# trainDF <- DF[ splitIndex,]
# testDF  <- DF[-splitIndex,]
# 
# DFint <- rbind(int_truth, int_lies)
# #write.csv2(DFint, "./df/intensity.csv", row.names = F)
# splitIndex <- createDataPartition(DFint[,truthful], p = .75, list = FALSE, times = 1)
# trainIntDF <- DFint[ splitIndex,]
# testIntDF  <- DFint[-splitIndex,]
# 
# ALL <- rbind(ALLT, ALLL)
# #write.csv2(ALL, "./df/combined.csv", row.names = F)
# splitIndex <- createDataPartition(ALL[,truthful], p = .70, list = FALSE, times = 1)
# ALL_train <- ALL[ splitIndex,]
# ALL_test  <- ALL[-splitIndex,]
```


Correlation
```{r}
correlation <- cor(ALL_train[,-c("truthful")])
rcorrelation <- rcorr(as.matrix(correlation))

corrplot(
  correlation,
  method = "square",
  type = "lower",
  order = "FPC",
  col = brewer.pal(n = 8, name = "RdBu"),
  cl.ratio = 0.2, cl.align = "r", tl.srt = 360, tl.col = "black", tl.cex = 0.65
)

highlyCorrelated <- findCorrelation(correlation, cutoff=0.5, names = T, exact = T)

# makeAllCorrMatrix(truth_test[,-c("truthful")])
# makeAllCorrMatrix(trainDF[,-c("truthful")])
# makeAllCorrMatrix(truth_train)
# makeAllCorrMatrix(tint_test[,-c("truthful")])
# makeAllCorrMatrix(tint_train[,-c("truthful")])
# makeAllCorrMatrix(lies_test[,-c("truthful")])
# makeAllCorrMatrix(lies_train[,-c("truthful")])
# makeAllCorrMatrix(lint_test[,-c("truthful")])
# makeAllCorrMatrix(lint_train[,-c("truthful")])
```

Plots
```{r}
# Crate Lies/Truth for Counts
lies_tot <- rbind(plies_train, plies_test)
truth_tot <- rbind(ptruth_test, ptruth_train)

# Lies
lies <- round(colSums(lies_tot[,-c("truthful")]/nrow(lies_tot)), 3)
lies <- enframe(lies, name = "au", value = "lies_occ")
lies <- data.frame(lies)

plies <- round(colSums(plies_train[,-c("truthful")]/nrow(plies_train)), 3)
plies <- enframe(plies, name = "au", value = "lies_occ")
plies <- data.frame(plies)

# Truths
truth <- round(colSums(truth_tot[,-c("truthful")]/nrow(lies_tot)), 3)
truth <- enframe(truth, name = "au", value = "truth_occ")
truth <- data.frame(truth)

ptruth <- round(colSums(ptruth_train[,-c("truthful")]/nrow(ptruth_train)), 3)
ptruth <- enframe(ptruth, name = "au", value = "truth_occ")
ptruth <- data.frame(ptruth)

# Merged
tl <- merge(lies, truth, by="au")
tl <- melt(tl, value.name = "occ")

ptl <- merge(plies, ptruth, by="au")
ptl <- melt(ptl, value.name = "occ")

# Occurences of AUs in lying train + test
ggplot(data = lies, aes(x = au, y = lies_occ)) +
  geom_bar(stat = "identity", color = "black", fill = "steelblue") +
  geom_text(aes(label = lies_occ), vjust = -0.5, size = 3.5) +
  theme(axis.text.x = element_text(angle = 90, hjust = 0.5))+
  labs(title = "Average AU Occurrences for deceptive training set") + xlab("# of AU") + ylab("Avg. occurence of AU")

# Occurences of AUs in truth train + test
ggplot(data = truth, aes(x = au, y = truth_occ)) +
  geom_bar(stat = "identity", color = "black", fill = "darkgreen") +
  geom_text(aes(label = truth_occ), vjust = -0.5, size = 3.5) +
  theme(axis.text.x = element_text(angle = 90, hjust = 0.5))+
  labs(title = "Average AU Occurrences for truthful training set") + xlab("# of AU") + ylab("Avg. occurence of AU")

# Occurences of AUs compared train + test
ggplot(data = tl, aes(x = au, y = occ, fill = variable)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.5), width = 0.5) +
  scale_fill_manual(values = c("purple", "orange")) +
  theme(axis.text.x = element_text(angle = 90, hjust = 0.5))+
  labs(title = "Compared Average AU Occurrences for training set") + xlab("# of AU") + ylab("Avg. occurence of AU")

# Occurences of AUs in lying train 
ggplot(data = plies, aes(x = au, y = lies_occ)) +
  geom_bar(stat = "identity", color = "black", fill = "steelblue") +
  geom_text(aes(label = lies_occ), vjust = -0.5, size = 3.5) +
  theme(axis.text.x = element_text(angle = 90, hjust = 0.5))+
  labs(title = "Average AU Occurrences for deceptive training set") + xlab("# of AU") + ylab("Avg. occurence of AU")

# Occurences of AUs in truth train 
ggplot(data = ptruth, aes(x = au, y = truth_occ)) +
  geom_bar(stat = "identity", color = "black", fill = "darkgreen") +
  geom_text(aes(label = truth_occ), vjust = -0.5, size = 3.5) +
  theme(axis.text.x = element_text(angle = 90, hjust = 0.5)) +
  labs(title = "Average AU Occurrences for truthful training set") + xlab("# of AU") + ylab("Avg. occurence of AU")

# Occurences of AUs compared train 
ggplot(data = ptl, aes(x = au, y = occ, fill = variable)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.5), width = 0.5) +
  scale_fill_manual(values = c("steelblue", "darkgreen"), labels=c("Deceptive", "Thruthful")) +
  theme(axis.text.x = element_text(angle = 90, hjust = 0.5)) +
  labs(title = "Compared Average AU Occurrences for training set") + xlab("# of AU") + ylab("Avg. occurence of AU") 


```

Feature Selection
```{r}
correlationMatrix <- cor(ALL_train[,-c("truthful")])
highlyCorrelated <- findCorrelation(correlationMatrix, cutoff=0.5)
print(highlyCorrelated)

control <- trainControl(method="repeatedcv", number=10, repeats=3)
model <- train(truthful~., data=ALL_train, method="lvq", preProcess="scale", trControl=control)
importance <- varImp(model, scale=FALSE)
print(importance)
plot(importance)

```


GLM
```{r}
# Presence
# glm.model <- glm(truthful ~ . , family = binomial, data = trainDF)
# #summary(glm.model)
# glm.pred <- predict(glm.model, testDF[,-c("truthful")], type = "response")
# glm.predicted = rep(0, nrow(testDF))
# glm.predicted[glm.pred > .5] = 1
# table(glm.predicted, testDF$truthful)
# 1 - mean(glm.predicted == testDF$truthful)

# # Intensity
# glm.model_int <- glm(truthful ~ ., family = binomial, data = trainIntDF)
# #summary(glm.model_int)
# glm.pred_int <- predict(glm.model_int, testIntDF, type = "response")
# glm.predicted_int = rep(0, nrow(testIntDF))
# glm.predicted_int[glm.pred_int > .5] = 1
# table(glm.predicted_int, testIntDF$truthful)
# 1 - mean(glm.predicted_int == testIntDF$truthful)

# Merged
glm.model_all <- glm(truthful ~ ., family = binomial, data = ALL_train)
#summary(glm.model_all)
glm.pred_all <- predict(glm.model_all, ALL_test[,-c("truthful")], type = "response")
glm.predicted_all = rep(0, nrow(ALL_test))
glm.predicted_all[glm.pred_all > .5] = 1
table(glm.predicted_all, ALL_test$truthful)
1 - mean(glm.predicted_all == ALL_test$truthful)
```

LDA
```{r}
# Presence
# lda.model <- lda(truthful ~ ., trainDF)
# lda.pred <- predict(lda.model, testDF)
# ct <- table(testDF$truthful, lda.pred$class)
# diag(prop.table(ct, 1))
# sum(diag(prop.table(ct)))

# Intensity
# lda.model_int <- lda(truthful ~ ., trainIntDF)
# lda.pred_int <- predict(lda.model_int, testIntDF)
# ct_int <- table(testIntDF$truthful, lda.pred_int$class)
# diag(prop.table(ct_int, 1))
# sum(diag(prop.table(ct_int)))

# Merged
lda.model_all <- lda(truthful ~ ., ALL_train)
lda.pred_all <- predict(lda.model_all, ALL_test)
ct_all <- table(ALL_test$truthful, lda.pred_all$class)
diag(prop.table(ct_all, 1))
sum(diag(prop.table(ct_all)))
```

QDA 
```{r}
# Presence
# qda.model <- qda(truthful ~ ., data = trainDF)
# qda.class=predict(qda.model, testDF)$class
# table(qda.class, testDF$truthful)
# mean(qda.class == testDF$truthful)

# # Intentsity
# qda.model_int <- qda(truthful ~ ., data = trainIntDF)
# qda.class_int <- predict(qda.model_int ,testIntDF)$class
# table(qda.class_int, testIntDF$truthful)
# mean(qda.class_int == testIntDF$truthful)

# Merged
qda.model_all <- qda(truthful ~ ., data = ALL_train)
qda.class_all <- predict(qda.model_all, ALL_test)$class
table(qda.class_all, ALL_test$truthful)
mean(qda.class_all == ALL_test$truthful)
```

Random Forests
```{r}
# # Presence
# rf.model <- randomForest(truthful ~ ., data = trainDF, ntree = 250)
# print(rf.model)
# importanceRF(rf.model)
# rf.pred <- predict(rf.model, testDF)
# table(rf.pred, testDF$truthful)
# mean(rf.pred == testDF$truthful)

# # Intensity
# rf.model_int <- randomForest(truthful ~ ., data = trainIntDF, ntree = 250)
# print(rf.model_int)
# importanceRF(rf.model_int)
# rf.pred_int <- predict(rf.model_int, testIntDF)
# table(rf.pred_int, testIntDF$truthful)
# mean(rf.pred_int == testIntDF$truthful)

# Merged
rf.model_all <- randomForest(truthful ~ ., data = ALL_train, ntree = 250)
print(rf.model_all)
importanceRF(rf.model_all)
rf.pred_all <- predict(rf.model_all, ALL_test)
table(rf.pred_all, ALL_test$truthful)
mean(rf.pred_all == ALL_test$truthful)

# Ranger Implementation
# rf.model_all_ranger <- ranger(truthful ~ ., data = ALL_train, num.trees = 250, write.forest = TRUE)
# rf.pred_all_ranger <- predict(rf.model_all_ranger, ALL_test)
# table(rf.pred_all_ranger, ALL_test$truthful)
# mean(rf.pred_all_ranger == ALL_test$truthful)

```

PCA
```{r}
is.numeric(trainIntDF[,0:3])

pca <- prcomp(trainIntDF[,0:17], scale. = TRUE, center = TRUE)
summary(pca)


plot(pca, type = "l")
fviz_pca_ind(pca,
             col.ind = "cos2", # Color by the quality of representation
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE     # Avoid text overlapping
             )
(pca2 <- prcomp(trainIntDF[,0:17], scale. = TRUE))
```

SVM
```{r}
# Presence

## Tuning

# svm.tuning = tune(svm, truthful ~ ., data=trainDF, kernel = "linear", ranges = list(cost=c(0.001, 0.01, 0.1, 1, 5, 10, 100)))
# obj <- tune.svm(truthful ~ ., data = trainDF, gamma = 2^(-1:1), cost = 2^(2:8), kernel = "radial")

## Linear
svm.model_lin <- svm(truthful ~ . , data = trainDF, type = "C-classification", kernel = "linear", cost = 10, scale = FALSE)
svm.pred_lin <- predict(svm.model_lin, testDF)
summary(svm.model_lin)
table(svm.pred_lin, testDF$truthful)
mean(svm.pred_lin == testDF$truthful)

## Radial Basis
svm.model_rb <- svm(truthful ~ . , data = trainDF, type = "C-classification", kernel = "radial")
svm.pred_rb <- predict(svm.model_rb, testDF)
summary(svm.model_rb)
table(svm.pred_rb, testDF$truthful)
mean(svm.pred_rb == testDF$truthful)

#trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
#svm_Linear <- train(truthful ~., data = trainDF, method = "svmLinear", trControl=trctrl, preProcess = c("center", "scale"), tuneLength = 10)

# Intensity

## Linear
svm.model_int_lin <- svm(truthful ~ . , data = trainIntDF, type = "C-classification", kernel = "linear", cost = 10, scale = FALSE)
svm.pred_int_lin <- predict(svm.model_int_lin, testIntDF)
ssummary(svm.model_int_lin)
table(svm.pred_int_lin, testIntDF$truthful)
mean(svm.pred_int_lin == testIntDF$truthful)

## Radial Basis
svm.model_int_rb <- svm(truthful ~ . , data = trainIntDF, type = "C-classification", kernel = "radial")
svm.pred_int_rb <- predict(svm.model_int_rb, testIntDF)
summary(svm.model_int_rb)
table(svm.pred_int_rb, testIntDF$truthful)
mean(svm.pred_int_rb == testIntDF$truthful)

# Total

## Linear
svm.model_lin_all <- svm(truthful ~ . , data = ALL_train, type = "C-classification", kernel = "linear", cost = 1, scale = FALSE)
svm.pred_lin_all <- predict(svm.model_lin_all, ALL_test)
summary(svm.model_lin_all)
table(svm.pred_lin_all, ALL_test$truthful)
mean(svm.pred_lin_all == ALL_test$truthful)

## Radial Basis
svm.model_rb_all <- svm(truthful ~ . , data = ALL_train, type = "C-classification", kernel = "radial")
svm.pred_rb_all <- predict(svm.model_rb_all, ALL_test)
summary(svm.model_rb_all)
table(svm.pred_rb_all, ALL_test$truthful)
mean(svm.pred_rb_all == ALL_test$truthful)

```

NN
```{r}
nn.model <- nnet(truthful ~ ., data = ALL_train, size = 25, type = "class", maxit = 400)
nn.pred <- predict(nn.model, ALL_test, type = "class")
table(nn.pred, ALL_test$truthful)
mean(nn.pred == ALL_test$truthful)

```

