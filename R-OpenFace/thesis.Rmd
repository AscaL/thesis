---
title: "Thesis Clustering"
output: html_notebook
---

Libs
```{r}
library(tidyverse)
library(ggplot2)
library(MASS)
library(data.table)
library(reshape2)
library(dplyr)
library(caret)
library(Hmisc)
library(corrplot)
library(e1071)
library(ResourceSelection)
library(randomForest) # Random Forest
# library(ranger) # Faster Random Forest
library(nnet) # Neural Network
# library(keras) # NN + TensorFlow
library(xgboost)
library(factoextra)
```

Loading the Data - lies
```{r}
filenames_L_train <- list.files("./df/deceptive/train", pattern="*.csv", full.names=TRUE)
filenames_L_test <- list.files("./df/deceptive/test", pattern="*.csv", full.names=TRUE)
lies_train <- rbindlist(lapply(filenames_L_train, fread))
lies_test <- rbindlist(lapply(filenames_L_test, fread))

# Add "deceptive" to cols
lies_test$truthful <- rep(0, nrow(lies_test))
lies_test$truthful <- factor(lies_test$truthful)
lies_train$truthful <- rep(0, nrow(lies_train))
lies_train$truthful <- factor(lies_train$truthful)

# Remove Useless Columns
lies_train <- lies_train[,-c(1:5)]
lies_test <- lies_test[,-c(1:5)]

# Select Intensity Columns
lint_train <- lies_train[,c(1:17, 36)]
lint_test <- lies_test[,c(1:17, 36)]

# Select Presence Columns
plies_train <- lies_train[,-c(1:17)]
plies_test <- lies_test[,-c(1:17)]
```

Loading the Data - truth
```{r}
filenames_T_train <- list.files("./df/truthful/train", pattern="*.csv", full.names=TRUE)
filenames_T_test <- list.files("./df/truthful/test", pattern="*.csv", full.names=TRUE)
truth_train <- rbindlist(lapply(filenames_T_train, fread))
truth_test <- rbindlist(lapply(filenames_T_test, fread))

# Add "truthful" to cols
truth_test$truthful <- rep(1, nrow(truth_test))
truth_test$truthful <- factor(truth_test$truthful)
truth_train$truthful <- rep(1, nrow(truth_train))
truth_train$truthful <- factor(truth_train$truthful)

# Remove Useless Columns
truth_train <- truth_train[,-c(1:5)]
truth_test <- truth_test[,-c(1:5)]

# Select Intensity Columns
tint_train <- truth_train[,c(1:17, 36)]
tint_test <- truth_test[,c(1:17, 36)]

# Select Presence Columns
ptruth_train <- truth_train[,-c(1:17)]
ptruth_test <- truth_test[,-c(1:17)]
```

Create Train & Test set
```{r}
# Presence
trainDF <- rbind(ptruth_train, plies_train)
testDF <- rbind(ptruth_test, plies_test)

# Intensity
trainIntDF <- rbind(tint_train, lint_train)
testIntDF  <- rbind(tint_test, lint_test)

# Together
ALL_train <- rbind(truth_train, lies_train)
ALL_test <- rbind(truth_test, lies_test)
```


OLD Train & Test Set
```{r}
# # merge train and test
# DF <- rbind(truth, lies)
# #write.csv2(DF, "./df/presence.csv", row.names = F)
# splitIndex <- createDataPartition(DF[,truthful], p = .75, list = FALSE, times = 1)
# trainDF <- DF[ splitIndex,]
# testDF  <- DF[-splitIndex,]
# 
# DFint <- rbind(int_truth, int_lies)
# #write.csv2(DFint, "./df/intensity.csv", row.names = F)
# splitIndex <- createDataPartition(DFint[,truthful], p = .75, list = FALSE, times = 1)
# trainIntDF <- DFint[ splitIndex,]
# testIntDF  <- DFint[-splitIndex,]
# 
# ALL <- rbind(ALLT, ALLL)
# #write.csv2(ALL, "./df/combined.csv", row.names = F)
# splitIndex <- createDataPartition(ALL[,truthful], p = .70, list = FALSE, times = 1)
# ALL_train <- ALL[ splitIndex,]
# ALL_test  <- ALL[-splitIndex,]
```

Utils
```{r}
makeAllCorrMatrix <- function(data) {
  correlation <- cor(data)
  rcorrelation <- rcorr(as.matrix(data))
  # Standard Cor with 5 Clustering
  corrplot(
  correlation,
  order = "hclust",
  addrect = 5,
  title = "Standard Cor with 5 Clustering",
  mar = c(0, 0, 1, 0)
  )
  # Mixed Cor
  corrplot.mixed(
  correlation,
  lower.col = "black",
  number.cex = 0.55,
  tl.cex = 0.4,
  upper = "color",
  order = "hclust",
  tl.col = "black",
  tl.srt = 45,
  title = "Mixed Cor",
  mar = c(0, 0, 1, 0)
  )
  # Insignificant correlation are crossed
  corrplot(
  rcorrelation$r,
  type = "upper",
  order = "hclust",
  p.mat = rcorrelation$P,
  sig.level = 0.01,
  insig = "pch",
  title = "Insignificant Crossed",
  mar = c(0, 0, 1, 0)
  )
  # HeatMap
  col <- colorRampPalette(c("blue", "white", "red"))(20)
  heatmap(x = correlation, col = col, symm = TRUE)
  mtest <- cor.mtest(truth_test, conf.level = .95)
  # Visualize Confidence Intervals
  corrplot(
  correlation,
  p.mat = mtest$p,
  method = "color",
  type = "upper",
  sig.level = c(.001, .01, .05),
  pch.cex = .9,
  insig = "label_sig",
  pch.col = "white",
  order = "hclust",
  title = "Confidence Intervals",
  mar = c(0, 0, 1, 0)
  )
}

flattenCorrMatrix <- function(cormat, pmat) {
  ut <- upper.tri(cormat)
  data.frame(
    row = rownames(cormat)[row(cormat)[ut]],
    column = rownames(cormat)[col(cormat)[ut]],
    cor  =(cormat)[ut],
    p = pmat[ut]
    )
}

importanceRF <- function(rfmodel) {
  # Get importance
  importance <- importance(rfmodel)
  varImportance <- data.frame(Variables = row.names(importance),
  Importance = round(importance[, 'MeanDecreaseGini'], 2))
  
  # Create a rank variable based on importance
  rankImportance <- varImportance %>%
  mutate(Rank = paste0('#', dense_rank(desc(Importance))))
  
  # Use ggplot2 to visualize the relative importance of variables
  ggplot(rankImportance, aes(x = reorder(Variables, Importance),
  y = Importance)) +
  geom_bar(stat = 'identity', colour = 'black') +
  geom_text(
  aes(x = Variables, y = 0.5, label = Rank),
  hjust = 0,
  vjust = 0.55,
  size = 4,
  colour = 'lavender',
  fontface = 'bold'
  ) +
  labs(x = 'Variables', title = 'Relative Variable Importance') +
  coord_flip() +
  theme_minimal()
}
```

Correlation
```{r}
makeAllCorrMatrix(truth_test)
makeAllCorrMatrix(trainDF[,-c("truthful")])
makeAllCorrMatrix(truth_train)
makeAllCorrMatrix(tint_test)
makeAllCorrMatrix(tint_train)
makeAllCorrMatrix(lies_test)
makeAllCorrMatrix(lies_train)
makeAllCorrMatrix(lint_test)
makeAllCorrMatrix(lint_train)
```

Plots
```{r}
ggplot(data = train, aes(x = AU_TRAIN, y = TRUTH_TRAIN, fill = TRUTH_TRAIN)) +
  geom_bar(stat = "identity", color = "black") +
  geom_text(aes(label = TRUTH_TRAIN), vjust = -0.5, size = 3.5) +
  theme(axis.text.x = element_text(angle = 90, hjust = 0.5))

ggplot(data = train, aes(x = AU_TRAIN, y = LIE_TRAIN, fill = LIE_TRAIN)) +
  geom_bar(stat = "identity", color = "black") +
  geom_text(aes(label = LIE_TRAIN), vjust = -0.5, size = 3.5) +
  theme(axis.text.x = element_text(angle = 90, hjust = 0.5))

ggplot(data = test, aes(x = AU_TEST, y = TRUTH_TEST, fill = TRUTH_TEST)) +
  geom_bar(stat = "identity", color = "black") +
  geom_text(aes(label = TRUTH_TEST), vjust = -0.5, size = 3.5) +
  theme(axis.text.x = element_text(angle = 90, hjust = 0.5))

ggplot(data = test, aes(x = AU_TEST, y = LIE_TEST, fill = LIE_TEST)) +
  geom_bar(stat = "identity", color = "black") +
  geom_text(aes(label = LIE_TEST), vjust = -0.5, size = 3.5) +
  theme(axis.text.x = element_text(angle = 90, hjust = 0.5))
```

GLM
```{r}
# Presence
glm.model <- glm(truthful ~ . , family = binomial, data = trainDF)
#summary(glm.model)
glm.pred <- predict(glm.model, testDF[,-c("truthful")], type = "response")
glm.predicted = rep(0, 15417)
glm.predicted[glm.pred > .5] = 1
table(glm.predicted, testDF$truthful)
1 - mean(glm.predicted == testDF$truthful)

# Intensity
glm.model_int <- glm(truthful ~ ., family = binomial, data = trainIntDF)
#summary(glm.model_int)
glm.pred_int <- predict(glm.model_int, testIntDF, type = "response")
glm.predicted_int = rep(0, 15417)
glm.predicted_int[glm.pred_int > .5] = 1
table(glm.predicted_int, testIntDF$truthful)
1 - mean(glm.predicted_int == testIntDF$truthful)

# Merged
glm.model_all <- glm(truthful ~ ., family = binomial, data = ALL_train)
#summary(glm.model_all)
glm.pred_all <- predict(glm.model_all, ALL_test, type = "response")
glm.predicted_all = rep(0, 15417)
glm.predicted_all[glm.pred_all > .5] = 1
table(glm.predicted_all, ALL_test$truthful)
1 - mean(glm.predicted_all == ALL_test$truthful)
```

LDA
```{r}
# Presence
lda.model <- lda(truthful ~ ., trainDF)
lda.pred <- predict(lda.model, testDF)
ct <- table(testDF$truthful, lda.pred$class)
diag(prop.table(ct, 1))
sum(diag(prop.table(ct)))

# Intensity
lda.model_int <- lda(truthful ~ ., trainIntDF)
lda.pred_int <- predict(lda.model_int, testIntDF)
ct_int <- table(testIntDF$truthful, lda.pred_int$class)
diag(prop.table(ct_int, 1))
sum(diag(prop.table(ct_int)))

# Merged
lda.model_all <- lda(truthful ~ ., ALL_train)
lda.pred_all <- predict(lda.model_all, ALL_test)
ct_all <- table(ALL_test$truthful, lda.pred_all$class)
diag(prop.table(ct_all, 1))
sum(diag(prop.table(ct_all)))
```

QDA 
```{r}
# Presence
qda.model <- qda(truthful ~ ., data = trainDF)
qda.class=predict(qda.model, testDF)$class
table(qda.class, testDF$truthful)
mean(qda.class == testDF$truthful)

# Intentsity
qda.model_int <- qda(truthful ~ ., data = trainIntDF)
qda.class_int <- predict(qda.model_int ,testIntDF)$class
table(qda.class_int, testIntDF$truthful)
mean(qda.class_int == testIntDF$truthful)

# Merged
qda.model_all <- qda(truthful ~ ., data = ALL_train)
qda.class_all <- predict(qda.model_all, ALL_test)$class
table(qda.class_all, ALL_test$truthful)
mean(qda.class_all == ALL_test$truthful)
```

Random Forests
```{r}
# Presence
rf.model <- randomForest(truthful ~ ., data = trainDF, ntree = 250)
print(rf.model)
importanceRF(rf.model)
rf.pred <- predict(rf.model, testDF)
table(rf.pred, testDF$truthful)
mean(rf.pred == testDF$truthful)

# Intensity
rf.model_int <- randomForest(truthful ~ ., data = trainIntDF, ntree = 250)
print(rf.model_int)
importanceRF(rf.model_int)
rf.pred_int <- predict(rf.model_int, testIntDF)
table(rf.pred_int, testIntDF$truthful)
mean(rf.pred_int == testIntDF$truthful)

# Merged
rf.model_all <- randomForest(truthful ~ ., data = ALL_train, ntree = 250)
print(rf.model_all)
importanceRF(rf.model_all)
rf.pred_all <- predict(rf.model_all, ALL_test)
table(rf.pred_all, ALL_test$truthful)
mean(rf.pred_all == ALL_test$truthful)

# Ranger Implementation
# rf.model_all_ranger <- ranger(truthful ~ ., data = ALL_train, num.trees = 250, write.forest = TRUE)
# rf.pred_all_ranger <- predict(rf.model_all_ranger, ALL_test)
# table(rf.pred_all_ranger, ALL_test$truthful)
# mean(rf.pred_all_ranger == ALL_test$truthful)

```

PCA
```{r}
is.numeric(trainIntDF[,0:3])

pca <- prcomp(trainIntDF[,0:17], scale. = TRUE, center = TRUE)
summary(pca)


plot(pca, type = "l")
fviz_pca_ind(pca,
             col.ind = "cos2", # Color by the quality of representation
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE     # Avoid text overlapping
             )
(pca2 <- prcomp(trainIntDF[,0:17], scale. = TRUE))
```

SVM
```{r}
# Presence

## Tuning

# svm.tuning = tune(svm, truthful ~ ., data=trainDF, kernel = "linear", ranges = list(cost=c(0.001, 0.01, 0.1, 1, 5, 10, 100)))
# obj <- tune.svm(truthful ~ ., data = trainDF, gamma = 2^(-1:1), cost = 2^(2:8), kernel = "radial")

## Linear
svm.model_lin <- svm(truthful ~ . , data = trainDF, type = "C-classification", kernel = "linear", cost = 10, scale = FALSE)
svm.pred_lin <- predict(svm.model_lin, testDF)
summary(svm.model_lin)
table(svm.pred_lin, testDF$truthful)
mean(svm.pred_lin == testDF$truthful)

## Radial Basis
svm.model_rb <- svm(truthful ~ . , data = trainDF, type = "C-classification", kernel = "radial")
svm.pred_rb <- predict(svm.model_rb, testDF)
summary(svm.model_rb)
table(svm.pred_rb, testDF$truthful)
mean(svm.pred_rb == testDF$truthful)

#trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
#svm_Linear <- train(truthful ~., data = trainDF, method = "svmLinear", trControl=trctrl, preProcess = c("center", "scale"), tuneLength = 10)

# Intensity

## Linear
svm.model_int_lin <- svm(truthful ~ . , data = trainIntDF, type = "C-classification", kernel = "linear", cost = 10, scale = FALSE)
svm.pred_int_lin <- predict(svm.model_int_lin, testIntDF)
ssummary(svm.model_int_lin)
table(svm.pred_int_lin, testIntDF$truthful)
mean(svm.pred_int_lin == testIntDF$truthful)

## Radial Basis
svm.model_int_rb <- svm(truthful ~ . , data = trainIntDF, type = "C-classification", kernel = "radial")
svm.pred_int_rb <- predict(svm.model_int_rb, testIntDF)
summary(svm.model_int_rb)
table(svm.pred_int_rb, testIntDF$truthful)
mean(svm.pred_int_rb == testIntDF$truthful)

# Total

## Linear
svm.model_lin_all <- svm(truthful ~ . , data = ALL_train, type = "C-classification", kernel = "linear", cost = 10, scale = FALSE)
svm.pred_lin_all <- predict(svm.model_lin_all, ALL_test)
summary(svm.model_lin_all)
table(svm.pred_lin_all, ALL_test$truthful)
mean(svm.pred_lin_all == ALL_test$truthful)

## Radial Basis
svm.model_rb_all <- svm(truthful ~ . , data = ALL_train, type = "C-classification", kernel = "radial")
svm.pred_rb_all <- predict(svm.model_rb_all, ALL_test)
summary(svm.model_rb_all)
table(svm.pred_rb_all, ALL_test$truthful)
mean(svm.pred_rb_all == ALL_test$truthful)

```

NN
```{r}
nn.model <- nnet(truthful ~ ., data = ALL_train, size = 25, type = "class", maxit = 400)
nn.pred <- predict(nn.model, ALL_test, type = "class")
table(nn.pred, ALL_test$truthful)
mean(nn.pred == ALL_test$truthful)

```

